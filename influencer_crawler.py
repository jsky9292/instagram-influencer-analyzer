#!/usr/bin/env python3
"""
Influencer Crawler
YouTube ì¸í”Œë£¨ì–¸ì„œ ì •ë³´ í¬ë¡¤ë§ í”„ë¡œê·¸ë¨
"""

import json
import time
import re
from datetime import datetime
from pathlib import Path
import pandas as pd

try:
    import yt_dlp
    import requests
    from bs4 import BeautifulSoup
    from tqdm import tqdm
except ImportError as e:
    print(f"í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
    print("\në‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
    print("pip install yt-dlp requests beautifulsoup4 pandas tqdm openpyxl")
    exit(1)


class InfluencerCrawler:
    def __init__(self):
        self.ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'extract_flat': True,
        }
        self.results = []
        
    def get_channel_info(self, channel_url):
        """
        YouTube ì±„ë„ ì •ë³´ ì¶”ì¶œ
        
        Args:
            channel_url: YouTube ì±„ë„ URL
            
        Returns:
            dict: ì±„ë„ ì •ë³´
        """
        try:
            with yt_dlp.YoutubeDL(self.ydl_opts) as ydl:
                info = ydl.extract_info(channel_url, download=False)
                
                channel_data = {
                    'ì±„ë„ëª…': info.get('channel', info.get('uploader', 'Unknown')),
                    'ì±„ë„_ID': info.get('channel_id', ''),
                    'ì±„ë„_URL': info.get('channel_url', channel_url),
                    'êµ¬ë…ììˆ˜': self._format_number(info.get('channel_follower_count', 0)),
                    'ì„¤ëª…': info.get('description', '')[:200],  # ì„¤ëª… ì²« 200ì
                    'ìˆ˜ì§‘ì‹œê°„': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                
                return channel_data
                
        except Exception as e:
            print(f"âŒ ì±„ë„ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def get_channel_videos(self, channel_url, max_videos=10):
        """
        ì±„ë„ì˜ ìµœê·¼ ë¹„ë””ì˜¤ ì •ë³´ ì¶”ì¶œ
        
        Args:
            channel_url: YouTube ì±„ë„ URL
            max_videos: ìˆ˜ì§‘í•  ìµœëŒ€ ë¹„ë””ì˜¤ ìˆ˜
            
        Returns:
            list: ë¹„ë””ì˜¤ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        videos = []
        
        try:
            ydl_opts = {
                'quiet': True,
                'extract_flat': 'in_playlist',
                'playlistend': max_videos,
            }
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                # ì±„ë„ì˜ uploads í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ URL êµ¬ì„±
                if '/channel/' in channel_url:
                    channel_id = channel_url.split('/channel/')[-1].split('/')[0]
                    uploads_url = f"https://www.youtube.com/channel/{channel_id}/videos"
                elif '/@' in channel_url:
                    uploads_url = channel_url.rstrip('/') + '/videos'
                else:
                    uploads_url = channel_url
                
                print(f"  ğŸ“¹ ë¹„ë””ì˜¤ ëª©ë¡ ìˆ˜ì§‘ ì¤‘: {uploads_url}")
                info = ydl.extract_info(uploads_url, download=False)
                
                entries = info.get('entries', [])[:max_videos]
                
                for entry in tqdm(entries, desc="  ë¹„ë””ì˜¤ ì •ë³´ ìˆ˜ì§‘"):
                    video_url = f"https://www.youtube.com/watch?v={entry['id']}"
                    
                    # ê° ë¹„ë””ì˜¤ì˜ ìƒì„¸ ì •ë³´ ì¶”ì¶œ
                    try:
                        video_info = ydl.extract_info(video_url, download=False)
                        
                        video_data = {
                            'ì œëª©': video_info.get('title', ''),
                            'URL': video_url,
                            'ì¡°íšŒìˆ˜': self._format_number(video_info.get('view_count', 0)),
                            'ì¢‹ì•„ìš”': self._format_number(video_info.get('like_count', 0)),
                            'ëŒ“ê¸€ìˆ˜': self._format_number(video_info.get('comment_count', 0)),
                            'ê¸¸ì´(ì´ˆ)': video_info.get('duration', 0),
                            'ì—…ë¡œë“œë‚ ì§œ': video_info.get('upload_date', ''),
                            'ì„¤ëª…': video_info.get('description', '')[:100],
                        }
                        
                        videos.append(video_data)
                        time.sleep(0.5)  # API ë¶€í•˜ ë°©ì§€
                        
                    except Exception as e:
                        print(f"    âš ï¸ ë¹„ë””ì˜¤ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                        continue
                        
        except Exception as e:
            print(f"âŒ ë¹„ë””ì˜¤ ëª©ë¡ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            
        return videos
    
    def search_channels(self, keyword, max_results=10):
        """
        í‚¤ì›Œë“œë¡œ YouTube ì±„ë„ ê²€ìƒ‰
        
        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            list: ì±„ë„ URL ë¦¬ìŠ¤íŠ¸
        """
        channels = []
        
        try:
            search_url = f"ytsearch{max_results}:{keyword} channel"
            
            with yt_dlp.YoutubeDL(self.ydl_opts) as ydl:
                info = ydl.extract_info(search_url, download=False)
                
                for entry in info.get('entries', []):
                    if entry.get('channel_url'):
                        channels.append(entry['channel_url'])
                        
        except Exception as e:
            print(f"âŒ ì±„ë„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            
        return channels
    
    def crawl_influencer(self, channel_url, include_videos=True, max_videos=5):
        """
        ë‹¨ì¼ ì¸í”Œë£¨ì–¸ì„œ ì •ë³´ í¬ë¡¤ë§
        
        Args:
            channel_url: ì±„ë„ URL
            include_videos: ë¹„ë””ì˜¤ ì •ë³´ í¬í•¨ ì—¬ë¶€
            max_videos: ìˆ˜ì§‘í•  ìµœëŒ€ ë¹„ë””ì˜¤ ìˆ˜
        """
        print(f"\nğŸ” í¬ë¡¤ë§ ì‹œì‘: {channel_url}")
        
        # ì±„ë„ ì •ë³´ ìˆ˜ì§‘
        channel_info = self.get_channel_info(channel_url)
        
        if channel_info:
            print(f"  âœ… ì±„ë„: {channel_info['ì±„ë„ëª…']}")
            print(f"  ğŸ‘¥ êµ¬ë…ì: {channel_info['êµ¬ë…ììˆ˜']}")
            
            result = {'channel': channel_info}
            
            # ë¹„ë””ì˜¤ ì •ë³´ ìˆ˜ì§‘
            if include_videos:
                videos = self.get_channel_videos(channel_url, max_videos)
                result['videos'] = videos
                print(f"  ğŸ“Š ìˆ˜ì§‘ëœ ë¹„ë””ì˜¤: {len(videos)}ê°œ")
            
            self.results.append(result)
            return result
        
        return None
    
    def crawl_multiple(self, channel_urls, include_videos=True, max_videos=5):
        """
        ì—¬ëŸ¬ ì¸í”Œë£¨ì–¸ì„œ ì •ë³´ ì¼ê´„ í¬ë¡¤ë§
        
        Args:
            channel_urls: ì±„ë„ URL ë¦¬ìŠ¤íŠ¸
            include_videos: ë¹„ë””ì˜¤ ì •ë³´ í¬í•¨ ì—¬ë¶€
            max_videos: ì±„ë„ë‹¹ ìˆ˜ì§‘í•  ìµœëŒ€ ë¹„ë””ì˜¤ ìˆ˜
        """
        print(f"\n{'='*50}")
        print(f"ì´ {len(channel_urls)}ê°œ ì±„ë„ í¬ë¡¤ë§ ì‹œì‘")
        print(f"{'='*50}")
        
        for url in channel_urls:
            self.crawl_influencer(url, include_videos, max_videos)
            time.sleep(2)  # ì„œë²„ ë¶€í•˜ ë°©ì§€
    
    def save_to_excel(self, filename='influencer_data.xlsx'):
        """
        ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ Excel íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            filename: ì €ì¥í•  íŒŒì¼ëª…
        """
        if not self.results:
            print("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì±„ë„ ì •ë³´ DataFrame
        channels_data = []
        videos_data = []
        
        for result in self.results:
            channel = result['channel']
            channels_data.append(channel)
            
            # ë¹„ë””ì˜¤ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if 'videos' in result:
                for video in result['videos']:
                    video['ì±„ë„ëª…'] = channel['ì±„ë„ëª…']
                    videos_data.append(video)
        
        # Excel íŒŒì¼ë¡œ ì €ì¥
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            # ì±„ë„ ì‹œíŠ¸
            df_channels = pd.DataFrame(channels_data)
            df_channels.to_excel(writer, sheet_name='ì±„ë„ì •ë³´', index=False)
            
            # ë¹„ë””ì˜¤ ì‹œíŠ¸
            if videos_data:
                df_videos = pd.DataFrame(videos_data)
                df_videos.to_excel(writer, sheet_name='ë¹„ë””ì˜¤ì •ë³´', index=False)
        
        print(f"\nâœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filename}")
        print(f"  - ì±„ë„: {len(channels_data)}ê°œ")
        print(f"  - ë¹„ë””ì˜¤: {len(videos_data)}ê°œ")
    
    def save_to_json(self, filename='influencer_data.json'):
        """
        ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            filename: ì €ì¥í•  íŒŒì¼ëª…
        """
        if not self.results:
            print("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… JSON ì €ì¥ ì™„ë£Œ: {filename}")
    
    def _format_number(self, num):
        """ìˆ«ìë¥¼ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if num >= 1000000:
            return f"{num/1000000:.1f}M"
        elif num >= 1000:
            return f"{num/1000:.1f}K"
        return str(num)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    crawler = InfluencerCrawler()
    
    # ì˜ˆì œ: íŠ¹ì • ì±„ë„ë“¤ í¬ë¡¤ë§
    sample_channels = [
        "https://www.youtube.com/@MrBeast",  # MrBeast
        "https://www.youtube.com/@PewDiePie",  # PewDiePie
        "https://www.youtube.com/@tseries",  # T-Series
    ]
    
    print("=" * 50)
    print("YouTube ì¸í”Œë£¨ì–¸ì„œ í¬ë¡¤ëŸ¬")
    print("=" * 50)
    
    while True:
        print("\në©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
        print("1. ë‹¨ì¼ ì±„ë„ í¬ë¡¤ë§")
        print("2. ì—¬ëŸ¬ ì±„ë„ í¬ë¡¤ë§ (ìƒ˜í”Œ)")
        print("3. í‚¤ì›Œë“œë¡œ ì±„ë„ ê²€ìƒ‰ í›„ í¬ë¡¤ë§")
        print("4. ì €ì¥ëœ ë°ì´í„° í™•ì¸")
        print("5. ì¢…ë£Œ")
        
        choice = input("\nì„ íƒ (1-5): ").strip()
        
        if choice == '1':
            url = input("ì±„ë„ URL ì…ë ¥: ").strip()
            include_videos = input("ë¹„ë””ì˜¤ ì •ë³´ë„ ìˆ˜ì§‘í• ê¹Œìš”? (y/n): ").lower() == 'y'
            
            if include_videos:
                max_videos = int(input("ìˆ˜ì§‘í•  ë¹„ë””ì˜¤ ìˆ˜ (ê¸°ë³¸ 5): ") or 5)
            else:
                max_videos = 0
            
            crawler.crawl_influencer(url, include_videos, max_videos)
            
            # ì €ì¥ ì˜µì…˜
            if input("\në°ì´í„°ë¥¼ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower() == 'y':
                crawler.save_to_excel()
                crawler.save_to_json()
        
        elif choice == '2':
            print("\nìƒ˜í”Œ ì±„ë„ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            crawler.crawl_multiple(sample_channels, include_videos=True, max_videos=3)
            
            # ì €ì¥
            crawler.save_to_excel('sample_influencers.xlsx')
            crawler.save_to_json('sample_influencers.json')
        
        elif choice == '3':
            keyword = input("ê²€ìƒ‰ í‚¤ì›Œë“œ ì…ë ¥: ").strip()
            max_results = int(input("ê²€ìƒ‰í•  ì±„ë„ ìˆ˜ (ê¸°ë³¸ 5): ") or 5)
            
            print(f"\n'{keyword}' ê´€ë ¨ ì±„ë„ ê²€ìƒ‰ ì¤‘...")
            channels = crawler.search_channels(keyword, max_results)
            
            if channels:
                print(f"\n{len(channels)}ê°œ ì±„ë„ ë°œê²¬:")
                for i, ch in enumerate(channels, 1):
                    print(f"  {i}. {ch}")
                
                if input("\nëª¨ë“  ì±„ë„ì„ í¬ë¡¤ë§í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower() == 'y':
                    crawler.crawl_multiple(channels, include_videos=True, max_videos=3)
                    crawler.save_to_excel(f'{keyword}_influencers.xlsx')
        
        elif choice == '4':
            if crawler.results:
                print(f"\ní˜„ì¬ ìˆ˜ì§‘ëœ ë°ì´í„°: {len(crawler.results)}ê°œ ì±„ë„")
                for result in crawler.results:
                    print(f"  - {result['channel']['ì±„ë„ëª…']}: {result['channel']['êµ¬ë…ììˆ˜']} êµ¬ë…ì")
            else:
                print("\nìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        elif choice == '5':
            print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        
        else:
            print("\nì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()