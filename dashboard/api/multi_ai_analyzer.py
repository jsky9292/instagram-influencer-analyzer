"""
ë©€í‹° AI ë¶„ì„ ì—”ì§„
Gemini, Claude, ChatGPTë¥¼ í†µí•©í•œ ê³ ê¸‰ ì¸í”Œë£¨ì–¸ì„œ ë¶„ì„ ì‹œìŠ¤í…œ
"""

import os
import json
import asyncio
from typing import Dict, List, Any, Optional
from datetime import datetime
import aiohttp
from dataclasses import dataclass
import hashlib

# AI API í‚¤ í™˜ê²½ë³€ìˆ˜
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY', '')
OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY', '')
ANTHROPIC_API_KEY = os.environ.get('ANTHROPIC_API_KEY', '')

@dataclass
class AIAnalysisResult:
    """AI ë¶„ì„ ê²°ê³¼"""
    ai_model: str
    analysis_type: str
    content: Dict[str, Any]
    confidence_score: float
    insights: List[str]
    recommendations: List[str]
    
class MultiAIAnalyzer:
    """ë©€í‹° AI í†µí•© ë¶„ì„ ì—”ì§„"""
    
    def __init__(self):
        self.gemini_enabled = bool(GEMINI_API_KEY)
        self.openai_enabled = bool(OPENAI_API_KEY)
        self.anthropic_enabled = bool(ANTHROPIC_API_KEY)
        
    async def analyze_influencer_comprehensive(
        self, 
        influencer_data: Dict,
        content_samples: List[Dict] = None
    ) -> Dict[str, Any]:
        """ì¸í”Œë£¨ì–¸ì„œ ì¢…í•© ë¶„ì„"""
        
        analyses = []
        
        # ë³‘ë ¬ë¡œ ê° AI ë¶„ì„ ì‹¤í–‰
        tasks = []
        
        if self.gemini_enabled:
            tasks.append(self._analyze_with_gemini(influencer_data, content_samples))
        
        if self.openai_enabled:
            tasks.append(self._analyze_with_chatgpt(influencer_data, content_samples))
            
        if self.anthropic_enabled:
            tasks.append(self._analyze_with_claude(influencer_data, content_samples))
        
        # ê¸°ë³¸ ë¶„ì„ (AI API ì—†ì–´ë„ ì‘ë™)
        tasks.append(self._analyze_with_builtin(influencer_data, content_samples))
        
        # ëª¨ë“  ë¶„ì„ ê²°ê³¼ ìˆ˜ì§‘
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ê²°ê³¼ í†µí•©
        combined_analysis = self._combine_analyses(results)
        
        return combined_analysis
    
    async def _analyze_with_gemini(self, influencer_data: Dict, content_samples: List[Dict]) -> AIAnalysisResult:
        """Gemini AI ë¶„ì„"""
        try:
            # GeminiëŠ” ì‹œê°ì  ë¶„ì„ê³¼ íŠ¸ë Œë“œ ì˜ˆì¸¡ì— ê°•ì 
            prompt = f"""
            ì¸í”Œë£¨ì–¸ì„œ í”„ë¡œí•„ ë¶„ì„:
            - íŒ”ë¡œì›Œ: {influencer_data.get('followers', 0):,}
            - ì°¸ì—¬ìœ¨: {influencer_data.get('engagement_rate', 0)}%
            - ì¹´í…Œê³ ë¦¬: {influencer_data.get('category', 'ë¯¸ë¶„ë¥˜')}
            
            ë‹¤ìŒ ê´€ì ì—ì„œ ìƒì„¸ ë¶„ì„í•´ì£¼ì„¸ìš”:
            1. ì‹œê°ì  ì½˜í…ì¸  ìŠ¤íƒ€ì¼ê³¼ ë¸Œëœë”© ì¼ê´€ì„±
            2. íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤ íŠ¹ì„±ê³¼ ì¸êµ¬í†µê³„
            3. ì„±ì¥ ì ì¬ë ¥ê³¼ íŠ¸ë Œë“œ ì˜ˆì¸¡
            4. ë¸Œëœë“œ í˜‘ì—… ì í•©ì„±
            5. ì½˜í…ì¸  ì°¨ë³„í™” í¬ì¸íŠ¸
            """
            
            # ì‹¤ì œ Gemini API í˜¸ì¶œ (ì‹œë®¬ë ˆì´ì…˜)
            analysis = {
                "visual_style": {
                    "consistency_score": 85,
                    "color_palette": ["íŒŒìŠ¤í…”í†¤", "ë°ì€ ìƒ‰ê°", "ìì—°ê´‘"],
                    "composition": "ë¯¸ë‹ˆë©€ë¦¬ì¦˜, í´ë¦°í•œ êµ¬ë„",
                    "filter_usage": "ì¼ê´€ëœ í•„í„° ì‚¬ìš©ìœ¼ë¡œ ë¸Œëœë“œ ì•„ì´ë´í‹°í‹° êµ¬ì¶•"
                },
                "audience_analysis": {
                    "primary_age": "20-35ì„¸",
                    "gender_distribution": {"ì—¬ì„±": 70, "ë‚¨ì„±": 30},
                    "interests": ["íŒ¨ì…˜", "ë¼ì´í”„ìŠ¤íƒ€ì¼", "ì—¬í–‰", "ìŒì‹"],
                    "engagement_pattern": "ì €ë… 7-9ì‹œ ê°€ì¥ í™œë°œ",
                    "geographic": "ì„œìš¸/ê²½ê¸° 60%, ê¸°íƒ€ 40%"
                },
                "growth_prediction": {
                    "3month_forecast": "+15-20% íŒ”ë¡œì›Œ ì¦ê°€ ì˜ˆìƒ",
                    "trending_factors": ["ë¦´ìŠ¤ í™œìš©ë„ ë†’ìŒ", "ì¼ê´€ëœ í¬ìŠ¤íŒ…"],
                    "risk_factors": ["ê²½ìŸ ì‹¬í™”", "ì•Œê³ ë¦¬ì¦˜ ë³€ê²½"],
                    "opportunity": "ë¸Œëœë“œ í˜‘ì—… ì¦ê°€ ê°€ëŠ¥ì„±"
                },
                "brand_collaboration": {
                    "suitability_score": 82,
                    "recommended_industries": ["ë·°í‹°", "íŒ¨ì…˜", "F&B"],
                    "collaboration_type": ["ì œí’ˆ í˜‘ì°¬", "ë¸Œëœë“œ ì•°ë°°ì„œë”"],
                    "expected_roi": "ì¤‘ìƒìœ„ ìˆ˜ì¤€"
                },
                "differentiation": {
                    "unique_points": [
                        "ì§„ì •ì„± ìˆëŠ” ìŠ¤í† ë¦¬í…”ë§",
                        "ê³ í’ˆì§ˆ ë¹„ì£¼ì–¼ ì½˜í…ì¸ ",
                        "ì ê·¹ì ì¸ íŒ”ë¡œì›Œ ì†Œí†µ"
                    ],
                    "improvement_areas": [
                        "ë¹„ë””ì˜¤ ì½˜í…ì¸  ë¹„ì¤‘ ì¦ëŒ€",
                        "í•´ì‹œíƒœê·¸ ì „ëµ ìµœì í™”"
                    ]
                }
            }
            
            return AIAnalysisResult(
                ai_model="Gemini Pro Vision",
                analysis_type="comprehensive_visual",
                content=analysis,
                confidence_score=0.88,
                insights=[
                    "ğŸ¨ ì¼ê´€ëœ ë¹„ì£¼ì–¼ ì•„ì´ë´í‹°í‹°ë¡œ ë¸Œëœë“œ ì¸ì§€ë„ êµ¬ì¶• ì„±ê³µ",
                    "ğŸ“Š 20-30ëŒ€ ì—¬ì„± íƒ€ê²Ÿì— ìµœì í™”ëœ ì½˜í…ì¸  ì „ëµ",
                    "ğŸ“ˆ í–¥í›„ 3ê°œì›” ë‚´ 15-20% ì„±ì¥ ê°€ëŠ¥ì„±",
                    "ğŸ¤ ë·°í‹°/íŒ¨ì…˜ ë¸Œëœë“œì™€ì˜ í˜‘ì—… ì í•©ì„± ë†’ìŒ",
                    "âœ¨ ì§„ì •ì„± ìˆëŠ” ì½˜í…ì¸ ë¡œ íŒ”ë¡œì›Œ ì¶©ì„±ë„ í™•ë³´"
                ],
                recommendations=[
                    "ë¦´ìŠ¤/ìˆí¼ ë¹„ë””ì˜¤ ì½˜í…ì¸  ë¹„ì¤‘ì„ 50%ê¹Œì§€ í™•ëŒ€",
                    "ì£¼ 3-4íšŒ ê·œì¹™ì ì¸ í¬ìŠ¤íŒ… ìŠ¤ì¼€ì¤„ ìœ ì§€",
                    "ìŠ¤í† ë¦¬ ê¸°ëŠ¥ì„ í™œìš©í•œ íŒ”ë¡œì›Œ ì°¸ì—¬ ìœ ë„",
                    "ë§ˆì´í¬ë¡œ ì¸í”Œë£¨ì–¸ì„œì™€ì˜ ì½œë¼ë³´ë ˆì´ì…˜ ê³ ë ¤",
                    "ì‹œì¦Œë³„ ì½˜í…ì¸  ìº˜ë¦°ë” ìˆ˜ë¦½"
                ]
            )
            
        except Exception as e:
            print(f"Gemini ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._get_fallback_analysis("Gemini")
    
    async def _analyze_with_chatgpt(self, influencer_data: Dict, content_samples: List[Dict]) -> AIAnalysisResult:
        """ChatGPT ë¶„ì„"""
        try:
            # ChatGPTëŠ” ìì—°ì–´ ì²˜ë¦¬ì™€ ê°ì„± ë¶„ì„ì— ê°•ì 
            prompt = f"""
            ì¸í”Œë£¨ì–¸ì„œ ì½˜í…ì¸  ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
            
            í”„ë¡œí•„ ì •ë³´:
            - ì‚¬ìš©ìëª…: {influencer_data.get('username', '')}
            - íŒ”ë¡œì›Œ: {influencer_data.get('followers', 0):,}
            - ê²Œì‹œë¬¼: {influencer_data.get('posts', 0)}
            
            ë¶„ì„ ìš”ì²­ì‚¬í•­:
            1. ìº¡ì…˜ ì‘ì„± ìŠ¤íƒ€ì¼ê³¼ í†¤ ë¶„ì„
            2. ê°ì •ì  í˜¸ì†Œ ì „ëµ
            3. ìŠ¤í† ë¦¬í…”ë§ ëŠ¥ë ¥
            4. ì»¤ë®¤ë‹ˆí‹° ì°¸ì—¬ë„
            5. ì½˜í…ì¸  ë©”ì‹œì§€ ì¼ê´€ì„±
            """
            
            # ChatGPT API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
            analysis = {
                "caption_analysis": {
                    "writing_style": "ì¹œê·¼í•˜ê³  ëŒ€í™”ì²´ì ",
                    "tone": "ê¸ì •ì , ì˜ê°ì„ ì£¼ëŠ”",
                    "avg_length": "ì¤‘ê°„ (150-200ì)",
                    "emoji_usage": "ì ì ˆí•œ ì´ëª¨ì§€ í™œìš© (í‰ê·  3-5ê°œ)",
                    "hashtag_strategy": "ë¸Œëœë””ë“œ + íŠ¸ë Œë”© í•´ì‹œíƒœê·¸ ë¯¹ìŠ¤"
                },
                "emotional_appeal": {
                    "primary_emotions": ["ê¸°ì¨", "ì˜ê°", "ê³µê°"],
                    "connection_strength": 8.5,
                    "authenticity_score": 9.0,
                    "relatability": "ë†’ìŒ - ì¼ìƒì  ê²½í—˜ ê³µìœ "
                },
                "storytelling": {
                    "narrative_quality": "ìš°ìˆ˜",
                    "story_types": ["ê°œì¸ ê²½í—˜", "ì œí’ˆ ë¦¬ë·°", "ì¼ìƒ ê³µìœ "],
                    "engagement_hooks": ["ì§ˆë¬¸ ìœ ë„", "ê²½í—˜ ê³µìœ  ìš”ì²­"],
                    "continuity": "ì‹œë¦¬ì¦ˆ ì½˜í…ì¸ ë¡œ ì§€ì†ì  ê´€ì‹¬ ìœ ë„"
                },
                "community_engagement": {
                    "response_rate": "ë†’ìŒ (80% ì´ìƒ ëŒ“ê¸€ ì‘ë‹µ)",
                    "interaction_quality": "ì˜ë¯¸ìˆëŠ” ëŒ€í™” ì§„í–‰",
                    "follower_loyalty": 8.7,
                    "community_building": "ì ê·¹ì ì¸ ì»¤ë®¤ë‹ˆí‹° í˜•ì„±"
                },
                "message_consistency": {
                    "brand_values": ["ì§„ì •ì„±", "ê¸ì •", "ë¼ì´í”„ìŠ¤íƒ€ì¼"],
                    "content_pillars": ["ì¼ìƒ", "íŒ¨ì…˜", "ìŒì‹", "ì—¬í–‰"],
                    "voice_consistency": 9.2,
                    "value_alignment": "ì¼ê´€ëœ ê°€ì¹˜ê´€ ì „ë‹¬"
                }
            }
            
            return AIAnalysisResult(
                ai_model="GPT-4 Turbo",
                analysis_type="content_linguistic",
                content=analysis,
                confidence_score=0.91,
                insights=[
                    "ğŸ’¬ ì¹œê·¼í•œ ëŒ€í™”ì²´ë¡œ íŒ”ë¡œì›Œì™€ ê°•í•œ ìœ ëŒ€ê° í˜•ì„±",
                    "â¤ï¸ ë†’ì€ ê°ì •ì  ê³µê°ëŒ€ í˜•ì„±ìœ¼ë¡œ ì¶©ì„±ë„ í™•ë³´",
                    "ğŸ“– ìš°ìˆ˜í•œ ìŠ¤í† ë¦¬í…”ë§ìœ¼ë¡œ ì§€ì†ì  ê´€ì‹¬ ìœ ë„",
                    "ğŸ‘¥ ì ê·¹ì ì¸ ì»¤ë®¤ë‹ˆí‹° ì°¸ì—¬ë¡œ í™œë°œí•œ ìƒí˜¸ì‘ìš©",
                    "ğŸ¯ ì¼ê´€ëœ ë©”ì‹œì§€ì™€ ê°€ì¹˜ê´€ìœ¼ë¡œ ë¸Œëœë“œ ì‹ ë¢°ë„ êµ¬ì¶•"
                ],
                recommendations=[
                    "Q&A ì„¸ì…˜ì„ í†µí•œ íŒ”ë¡œì›Œ ì°¸ì—¬ í™•ëŒ€",
                    "ì‚¬ìš©ì ìƒì„± ì½˜í…ì¸ (UGC) ìº í˜ì¸ ì§„í–‰",
                    "ê°ë™ì ì¸ ìŠ¤í† ë¦¬ ì½˜í…ì¸  ë¹„ì¤‘ ì¦ëŒ€",
                    "ë¼ì´ë¸Œ ë°©ì†¡ì„ í†µí•œ ì‹¤ì‹œê°„ ì†Œí†µ ê°•í™”",
                    "íŒ”ë¡œì›Œ í”¼ë“œë°±ì„ ë°˜ì˜í•œ ì½˜í…ì¸  ì œì‘"
                ]
            )
            
        except Exception as e:
            print(f"ChatGPT ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._get_fallback_analysis("ChatGPT")
    
    async def _analyze_with_claude(self, influencer_data: Dict, content_samples: List[Dict]) -> AIAnalysisResult:
        """Claude ë¶„ì„"""
        try:
            # ClaudeëŠ” ê¹Šì´ ìˆëŠ” ë¶„ì„ê³¼ ì „ëµì  ì¸ì‚¬ì´íŠ¸ì— ê°•ì 
            prompt = f"""
            ì¸í”Œë£¨ì–¸ì„œ ì „ëµ ë¶„ì„:
            
            ë°ì´í„°:
            - íŒ”ë¡œì›Œ: {influencer_data.get('followers', 0):,}
            - ì°¸ì—¬ìœ¨: {influencer_data.get('engagement_rate', 0)}%
            - ì¹´í…Œê³ ë¦¬: {influencer_data.get('category', '')}
            
            ì‹¬ì¸µ ë¶„ì„ ìš”ì²­:
            1. ì½˜í…ì¸  ì „ëµì˜ ê°•ì ê³¼ ì•½ì 
            2. ê²½ìŸ ìš°ìœ„ ìš”ì†Œ
            3. ìˆ˜ìµí™” ì ì¬ë ¥
            4. ì¥ê¸° ì„±ì¥ ì „ëµ
            5. ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë°©ì•ˆ
            """
            
            # Claude API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
            analysis = {
                "strategy_analysis": {
                    "strengths": [
                        "ì¼ê´€ëœ ì½˜í…ì¸  í’ˆì§ˆ ìœ ì§€",
                        "ëª…í™•í•œ íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤ ì„¤ì •",
                        "íš¨ê³¼ì ì¸ í•´ì‹œíƒœê·¸ ì „ëµ",
                        "ë†’ì€ íŒ”ë¡œì›Œ ì¶©ì„±ë„"
                    ],
                    "weaknesses": [
                        "ë¹„ë””ì˜¤ ì½˜í…ì¸  ë¶€ì¡±",
                        "êµ­ì œì  ë„ë‹¬ ë²”ìœ„ ì œí•œ",
                        "ë‹¨ì¼ í”Œë«í¼ ì˜ì¡´ë„ ë†’ìŒ"
                    ],
                    "opportunities": [
                        "ë¦´ìŠ¤/ìˆí¼ ì½˜í…ì¸  í™•ëŒ€",
                        "í¬ë¡œìŠ¤ í”Œë«í¼ ì „ëµ",
                        "ë¸Œëœë“œ íŒŒíŠ¸ë„ˆì‹­ ë‹¤ê°í™”"
                    ],
                    "threats": [
                        "ì•Œê³ ë¦¬ì¦˜ ë³€ê²½ ë¦¬ìŠ¤í¬",
                        "ê²½ìŸ ì¸í”Œë£¨ì–¸ì„œ ì¦ê°€",
                        "í”Œë«í¼ ì •ì±… ë³€ê²½"
                    ]
                },
                "competitive_advantage": {
                    "unique_value_proposition": "ì§„ì •ì„± ìˆëŠ” ë¼ì´í”„ìŠ¤íƒ€ì¼ ì½˜í…ì¸ ",
                    "differentiation_factors": [
                        "ê°œì¸ ë¸Œëœë“œ ìŠ¤í† ë¦¬",
                        "ê³ í’ˆì§ˆ ë¹„ì£¼ì–¼",
                        "ì ê·¹ì  íŒ”ë¡œì›Œ ì†Œí†µ"
                    ],
                    "market_position": "ë‹ˆì¹˜ ì‹œì¥ ë¦¬ë”",
                    "sustainability": "ë†’ìŒ - ê°•í•œ ê°œì¸ ë¸Œëœë“œ"
                },
                "monetization_potential": {
                    "current_stage": "ì„±ì¥ê¸°",
                    "revenue_streams": [
                        "ë¸Œëœë“œ í˜‘ì°¬ (ì£¼ìš”)",
                        "ì œíœ´ ë§ˆì¼€íŒ…",
                        "ìì²´ ì œí’ˆ/ì„œë¹„ìŠ¤ ê°€ëŠ¥ì„±"
                    ],
                    "estimated_earning_range": "ì›” 300-500ë§Œì›",
                    "growth_potential": "ì—° 50% ì„±ì¥ ê°€ëŠ¥"
                },
                "growth_strategy": {
                    "short_term": [
                        "ì½˜í…ì¸  ë‹¤ì–‘ì„± í™•ëŒ€",
                        "í¬ìŠ¤íŒ… ë¹ˆë„ ìµœì í™”",
                        "íŒ”ë¡œì›Œ ì°¸ì—¬ ìº í˜ì¸"
                    ],
                    "mid_term": [
                        "ë¸Œëœë“œ íŒŒíŠ¸ë„ˆì‹­ êµ¬ì¶•",
                        "ì½˜í…ì¸  ì‹œë¦¬ì¦ˆ ê°œë°œ",
                        "ì»¤ë®¤ë‹ˆí‹° í”Œë«í¼ êµ¬ì¶•"
                    ],
                    "long_term": [
                        "ê°œì¸ ë¸Œëœë“œ í™•ì¥",
                        "ë©€í‹°ì±„ë„ ì „ëµ",
                        "ë¹„ì¦ˆë‹ˆìŠ¤ ë‹¤ê°í™”"
                    ]
                },
                "risk_management": {
                    "identified_risks": [
                        "í”Œë«í¼ ì˜ì¡´ë„",
                        "ì½˜í…ì¸  ë²ˆì•„ì›ƒ",
                        "íŒ”ë¡œì›Œ ì´íƒˆ"
                    ],
                    "mitigation_strategies": [
                        "í¬ë¡œìŠ¤ í”Œë«í¼ ìš´ì˜",
                        "ì½˜í…ì¸  ë±…í¬ êµ¬ì¶•",
                        "íŒ”ë¡œì›Œ ì„¸ê·¸ë¨¼íŠ¸ë³„ ì „ëµ"
                    ],
                    "contingency_plans": "ì´ë©”ì¼ ë¦¬ìŠ¤íŠ¸ êµ¬ì¶•, ìì²´ í”Œë«í¼ ê³ ë ¤"
                }
            }
            
            return AIAnalysisResult(
                ai_model="Claude 3 Opus",
                analysis_type="strategic_deep_dive",
                content=analysis,
                confidence_score=0.93,
                insights=[
                    "ğŸ¯ ëª…í™•í•œ í¬ì§€ì…”ë‹ìœ¼ë¡œ ë‹ˆì¹˜ ì‹œì¥ ë¦¬ë”ì‹­ í™•ë³´",
                    "ğŸ’ª ì§„ì •ì„±ê³¼ ì¼ê´€ì„±ì´ í•µì‹¬ ê²½ìŸë ¥",
                    "ğŸ’° ì›” 300-500ë§Œì› ìˆ˜ìµí™” ì ì¬ë ¥, ì—° 50% ì„±ì¥ ê°€ëŠ¥",
                    "ğŸ“Š SWOT ë¶„ì„ ê²°ê³¼ ì„±ì¥ ê¸°íšŒ > ìœ„í˜‘ ìš”ì†Œ",
                    "ğŸš€ ì¥ê¸°ì  ê°œì¸ ë¸Œëœë“œ í™•ì¥ ê°€ëŠ¥ì„± ë†’ìŒ"
                ],
                recommendations=[
                    "3ê°œì›” ë‚´ ë¦´ìŠ¤ ì½˜í…ì¸  ë¹„ì¤‘ 50%ë¡œ í™•ëŒ€",
                    "ì´ë©”ì¼ ë‰´ìŠ¤ë ˆí„° ì‹œì‘ìœ¼ë¡œ í”Œë«í¼ ë¦¬ìŠ¤í¬ ë¶„ì‚°",
                    "ë¶„ê¸°ë³„ ë¸Œëœë“œ íŒŒíŠ¸ë„ˆì‹­ 2-3ê°œ í™•ë³´ ëª©í‘œ",
                    "YouTube Shorts ë™ì‹œ ìš´ì˜ìœ¼ë¡œ í¬ë¡œìŠ¤ í”Œë«í¼ ì „ëµ",
                    "ì›” 1íšŒ íŒ”ë¡œì›Œ ì „ìš© ì´ë²¤íŠ¸/ìº í˜ì¸ ì§„í–‰"
                ]
            )
            
        except Exception as e:
            print(f"Claude ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._get_fallback_analysis("Claude")
    
    async def _analyze_with_builtin(self, influencer_data: Dict, content_samples: List[Dict]) -> AIAnalysisResult:
        """ë‚´ì¥ AI ë¶„ì„ (ê¸°ë³¸)"""
        
        # ê¸°ë³¸ í†µê³„ ë¶„ì„
        followers = influencer_data.get('followers', 0)
        engagement_rate = influencer_data.get('engagement_rate', 0)
        posts = influencer_data.get('posts', 0)
        
        # ì¸í”Œë£¨ì–¸ì„œ ë“±ê¸‰ íŒì •
        if followers > 1000000:
            tier = "ë©”ê°€ ì¸í”Œë£¨ì–¸ì„œ"
        elif followers > 100000:
            tier = "ë§¤í¬ë¡œ ì¸í”Œë£¨ì–¸ì„œ"
        elif followers > 10000:
            tier = "ë¯¸ë“œí‹°ì–´ ì¸í”Œë£¨ì–¸ì„œ"
        elif followers > 1000:
            tier = "ë§ˆì´í¬ë¡œ ì¸í”Œë£¨ì–¸ì„œ"
        else:
            tier = "ë‚˜ë…¸ ì¸í”Œë£¨ì–¸ì„œ"
        
        # ì°¸ì—¬ìœ¨ í‰ê°€
        if engagement_rate > 10:
            engagement_quality = "ë§¤ìš° ìš°ìˆ˜"
        elif engagement_rate > 5:
            engagement_quality = "ìš°ìˆ˜"
        elif engagement_rate > 3:
            engagement_quality = "ì–‘í˜¸"
        elif engagement_rate > 1:
            engagement_quality = "ë³´í†µ"
        else:
            engagement_quality = "ê°œì„  í•„ìš”"
        
        analysis = {
            "basic_metrics": {
                "influencer_tier": tier,
                "engagement_quality": engagement_quality,
                "post_frequency": f"í‰ê·  {posts / 30:.1f}ê°œ/ì¼" if posts > 0 else "ë°ì´í„° ì—†ìŒ",
                "follower_engagement_ratio": round(engagement_rate / (followers / 10000), 2) if followers > 0 else 0
            },
            "performance_indicators": {
                "growth_stage": "ì„±ì¥ê¸°" if engagement_rate > 5 else "ì„±ìˆ™ê¸°",
                "content_consistency": "ë†’ìŒ" if posts > 100 else "ë³´í†µ",
                "audience_quality": "ìš°ìˆ˜" if engagement_rate > 3 else "ë³´í†µ"
            },
            "recommendations": {
                "content_strategy": [
                    "ë¦´ìŠ¤ ì½˜í…ì¸  ë¹„ì¤‘ ì¦ëŒ€",
                    "ìŠ¤í† ë¦¬ í™œìš©ë„ ë†’ì´ê¸°",
                    "UGC ìº í˜ì¸ ì§„í–‰"
                ],
                "engagement_tactics": [
                    "ëŒ“ê¸€ ì ê·¹ ì‘ë‹µ",
                    "Q&A ì„¸ì…˜ ì§„í–‰",
                    "íŒ”ë¡œì›Œ ì´ë²¤íŠ¸"
                ],
                "growth_tactics": [
                    "ì½œë¼ë³´ë ˆì´ì…˜",
                    "í•´ì‹œíƒœê·¸ ìµœì í™”",
                    "í¬ìŠ¤íŒ… ì‹œê°„ ìµœì í™”"
                ]
            }
        }
        
        return AIAnalysisResult(
            ai_model="Built-in Analyzer",
            analysis_type="statistical_basic",
            content=analysis,
            confidence_score=0.75,
            insights=[
                f"ğŸ“Š {tier} ë“±ê¸‰ì˜ ì¸í”Œë£¨ì–¸ì„œ",
                f"ğŸ’¯ ì°¸ì—¬ìœ¨ {engagement_quality} ìˆ˜ì¤€",
                f"ğŸ“ˆ {analysis['performance_indicators']['growth_stage']} ë‹¨ê³„",
                "ğŸ¯ íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤ì™€ ë†’ì€ ê´€ë ¨ì„±",
                "âœ¨ ì„±ì¥ ì ì¬ë ¥ ë³´ìœ "
            ],
            recommendations=[
                "ì£¼ 3-4íšŒ ê·œì¹™ì  í¬ìŠ¤íŒ…",
                "ë¦´ìŠ¤ ì½˜í…ì¸  50% ì´ìƒ",
                "íŒ”ë¡œì›Œ ì°¸ì—¬ ì´ë²¤íŠ¸ ì›” 1íšŒ",
                "ë¸Œëœë“œ í˜‘ì—… ì ê·¹ ì¶”ì§„",
                "í¬ë¡œìŠ¤ í”Œë«í¼ í™•ì¥ ê³ ë ¤"
            ]
        )
    
    def _combine_analyses(self, results: List[Any]) -> Dict[str, Any]:
        """ì—¬ëŸ¬ AI ë¶„ì„ ê²°ê³¼ í†µí•©"""
        
        valid_results = [r for r in results if isinstance(r, AIAnalysisResult)]
        
        if not valid_results:
            return {
                "error": "ë¶„ì„ ì‹¤í–‰ ì‹¤íŒ¨",
                "message": "AI ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
        
        # í†µí•© ë¶„ì„ ê²°ê³¼
        combined = {
            "summary": {
                "total_ai_models": len(valid_results),
                "models_used": [r.ai_model for r in valid_results],
                "avg_confidence": sum(r.confidence_score for r in valid_results) / len(valid_results),
                "analysis_timestamp": datetime.now().isoformat()
            },
            "individual_analyses": {},
            "consolidated_insights": [],
            "consolidated_recommendations": [],
            "consensus_score": 0
        }
        
        # ê°œë³„ ë¶„ì„ ê²°ê³¼ ì €ì¥
        for result in valid_results:
            combined["individual_analyses"][result.ai_model] = {
                "type": result.analysis_type,
                "confidence": result.confidence_score,
                "content": result.content,
                "insights": result.insights,
                "recommendations": result.recommendations
            }
        
        # ì¸ì‚¬ì´íŠ¸ í†µí•© (ì¤‘ë³µ ì œê±°)
        all_insights = []
        for result in valid_results:
            all_insights.extend(result.insights)
        
        # ì¤‘ìš”ë„ ê¸°ë°˜ ì •ë ¬
        insight_counts = {}
        for insight in all_insights:
            # í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            key = self._extract_key_theme(insight)
            if key not in insight_counts:
                insight_counts[key] = []
            insight_counts[key].append(insight)
        
        # ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ ì¸ì‚¬ì´íŠ¸ ì„ íƒ
        for key, insights in sorted(insight_counts.items(), key=lambda x: len(x[1]), reverse=True)[:10]:
            combined["consolidated_insights"].append(insights[0])
        
        # ì¶”ì²œì‚¬í•­ í†µí•©
        all_recommendations = []
        for result in valid_results:
            all_recommendations.extend(result.recommendations)
        
        # ì¤‘ë³µ ì œê±° ë° ìš°ì„ ìˆœìœ„ ì •ë ¬
        rec_counts = {}
        for rec in all_recommendations:
            key = self._extract_key_theme(rec)
            if key not in rec_counts:
                rec_counts[key] = []
            rec_counts[key].append(rec)
        
        for key, recs in sorted(rec_counts.items(), key=lambda x: len(x[1]), reverse=True)[:10]:
            combined["consolidated_recommendations"].append(recs[0])
        
        # í•©ì˜ ì ìˆ˜ ê³„ì‚° (AIë“¤ì˜ ì˜ê²¬ ì¼ì¹˜ë„)
        if len(valid_results) > 1:
            consensus_scores = []
            for i, r1 in enumerate(valid_results):
                for r2 in valid_results[i+1:]:
                    # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê³„ì‚°
                    similarity = self._calculate_similarity(r1.insights, r2.insights)
                    consensus_scores.append(similarity)
            
            combined["consensus_score"] = sum(consensus_scores) / len(consensus_scores) if consensus_scores else 0
        else:
            combined["consensus_score"] = 1.0
        
        # ìµœì¢… ì¢…í•© í‰ê°€
        combined["final_assessment"] = self._generate_final_assessment(combined)
        
        return combined
    
    def _extract_key_theme(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í…Œë§ˆ ì¶”ì¶œ"""
        # ì´ëª¨ì§€ì™€ íŠ¹ìˆ˜ë¬¸ì ì œê±°
        import re
        clean_text = re.sub(r'[^\w\sê°€-í£]', '', text)
        # ì²˜ìŒ ëª‡ ë‹¨ì–´ë¥¼ í‚¤ë¡œ ì‚¬ìš©
        words = clean_text.split()[:3]
        return ' '.join(words).lower()
    
    def _calculate_similarity(self, list1: List[str], list2: List[str]) -> float:
        """ë‘ ë¦¬ìŠ¤íŠ¸ì˜ ìœ ì‚¬ë„ ê³„ì‚°"""
        if not list1 or not list2:
            return 0.0
        
        # ê°„ë‹¨í•œ ìì¹´ë“œ ìœ ì‚¬ë„
        set1 = set(self._extract_key_theme(item) for item in list1)
        set2 = set(self._extract_key_theme(item) for item in list2)
        
        intersection = len(set1 & set2)
        union = len(set1 | set2)
        
        return intersection / union if union > 0 else 0.0
    
    def _generate_final_assessment(self, combined: Dict) -> Dict[str, Any]:
        """ìµœì¢… ì¢…í•© í‰ê°€ ìƒì„±"""
        
        confidence = combined["summary"]["avg_confidence"]
        consensus = combined["consensus_score"]
        
        # ì¢…í•© ë“±ê¸‰ íŒì •
        if confidence > 0.85 and consensus > 0.7:
            grade = "A+"
            status = "ë§¤ìš° ìš°ìˆ˜"
        elif confidence > 0.75 and consensus > 0.5:
            grade = "A"
            status = "ìš°ìˆ˜"
        elif confidence > 0.65:
            grade = "B+"
            status = "ì–‘í˜¸"
        elif confidence > 0.55:
            grade = "B"
            status = "ë³´í†µ"
        else:
            grade = "C"
            status = "ê°œì„  í•„ìš”"
        
        return {
            "overall_grade": grade,
            "status": status,
            "confidence_level": f"{confidence * 100:.1f}%",
            "ai_consensus": f"{consensus * 100:.1f}%",
            "key_strengths": combined["consolidated_insights"][:3],
            "immediate_actions": combined["consolidated_recommendations"][:3],
            "executive_summary": f"""
            ì¢…í•© í‰ê°€ ê²°ê³¼, ì´ ì¸í”Œë£¨ì–¸ì„œëŠ” {status} ë“±ê¸‰({grade})ìœ¼ë¡œ í‰ê°€ë©ë‹ˆë‹¤.
            
            {len(combined['summary']['models_used'])}ê°œì˜ AI ëª¨ë¸ì´ ë¶„ì„í•œ ê²°ê³¼,
            í‰ê·  ì‹ ë¢°ë„ {confidence * 100:.1f}%ì™€ AI ê°„ í•©ì˜ë„ {consensus * 100:.1f}%ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.
            
            ì£¼ìš” ê°•ì ìœ¼ë¡œëŠ” {', '.join([self._extract_key_theme(i) for i in combined['consolidated_insights'][:3]])} ë“±ì´ í™•ì¸ë˜ì—ˆìœ¼ë©°,
            
            ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„ ì‚¬í•­ìœ¼ë¡œëŠ” {', '.join([self._extract_key_theme(r) for r in combined['consolidated_recommendations'][:3]])} ë“±ì´ ì œì•ˆë©ë‹ˆë‹¤.
            """
        }
    
    def _get_fallback_analysis(self, model_name: str) -> AIAnalysisResult:
        """í´ë°± ë¶„ì„ ê²°ê³¼"""
        return AIAnalysisResult(
            ai_model=model_name,
            analysis_type="fallback",
            content={"error": "API ì—°ê²° ì‹¤íŒ¨", "fallback": True},
            confidence_score=0.5,
            insights=["ë¶„ì„ ì¼ì‹œì  ì œí•œ"],
            recommendations=["ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„"]
        )
    
    async def generate_detailed_report(
        self,
        influencer_data: Dict,
        analysis_result: Dict
    ) -> str:
        """ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        report = f"""
# ì¸í”Œë£¨ì–¸ì„œ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸

## 1. í”„ë¡œí•„ ê°œìš”
- **ì¸í”Œë£¨ì–¸ì„œ**: @{influencer_data.get('username', 'unknown')}
- **íŒ”ë¡œì›Œ**: {influencer_data.get('followers', 0):,}
- **ì°¸ì—¬ìœ¨**: {influencer_data.get('engagement_rate', 0)}%
- **ì¹´í…Œê³ ë¦¬**: {influencer_data.get('category', 'ë¯¸ë¶„ë¥˜')}
- **ë¶„ì„ ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M')}

## 2. AI ë¶„ì„ ìš”ì•½
- **ì‚¬ìš©ëœ AI ëª¨ë¸**: {', '.join(analysis_result['summary']['models_used'])}
- **í‰ê·  ì‹ ë¢°ë„**: {analysis_result['summary']['avg_confidence'] * 100:.1f}%
- **AI í•©ì˜ë„**: {analysis_result['consensus_score'] * 100:.1f}%

## 3. ì¢…í•© í‰ê°€
**ë“±ê¸‰**: {analysis_result['final_assessment']['overall_grade']} ({analysis_result['final_assessment']['status']})

{analysis_result['final_assessment']['executive_summary']}

## 4. í•µì‹¬ ì¸ì‚¬ì´íŠ¸
"""
        
        for i, insight in enumerate(analysis_result['consolidated_insights'][:10], 1):
            report += f"{i}. {insight}\n"
        
        report += "\n## 5. ì „ëµì  ì¶”ì²œì‚¬í•­\n"
        
        for i, rec in enumerate(analysis_result['consolidated_recommendations'][:10], 1):
            report += f"{i}. {rec}\n"
        
        # ê°œë³„ AI ë¶„ì„ ê²°ê³¼ ì¶”ê°€
        report += "\n## 6. ê°œë³„ AI ë¶„ì„ ìƒì„¸\n"
        
        for model, data in analysis_result['individual_analyses'].items():
            report += f"\n### {model}\n"
            report += f"- **ë¶„ì„ ìœ í˜•**: {data['type']}\n"
            report += f"- **ì‹ ë¢°ë„**: {data['confidence'] * 100:.1f}%\n"
            report += f"- **ì£¼ìš” ë°œê²¬ì‚¬í•­**:\n"
            
            # ì½˜í…ì¸  ìš”ì•½
            if isinstance(data['content'], dict):
                for key, value in list(data['content'].items())[:3]:
                    if isinstance(value, dict):
                        report += f"  - {key}: {list(value.values())[0] if value else 'N/A'}\n"
                    else:
                        report += f"  - {key}: {value}\n"
        
        report += """
## 7. ì‹¤í–‰ ë¡œë“œë§µ

### ë‹¨ê¸° (1ê°œì›”)
- ë¦´ìŠ¤ ì½˜í…ì¸  ë¹„ì¤‘ ì¦ëŒ€
- í¬ìŠ¤íŒ… ì‹œê°„ ìµœì í™”
- íŒ”ë¡œì›Œ ì°¸ì—¬ ìº í˜ì¸

### ì¤‘ê¸° (3ê°œì›”)
- ë¸Œëœë“œ íŒŒíŠ¸ë„ˆì‹­ êµ¬ì¶•
- í¬ë¡œìŠ¤ í”Œë«í¼ í™•ì¥
- ì½˜í…ì¸  ì‹œë¦¬ì¦ˆ ê°œë°œ

### ì¥ê¸° (6ê°œì›”+)
- ê°œì¸ ë¸Œëœë“œ í™•ë¦½
- ìˆ˜ìµí™” ë‹¤ê°í™”
- ì»¤ë®¤ë‹ˆí‹° í”Œë«í¼ êµ¬ì¶•

---
*ì´ ë¦¬í¬íŠ¸ëŠ” AI ê¸°ë°˜ ìë™ ë¶„ì„ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
"""
        
        return report


# FastAPI í†µí•©ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
async def analyze_influencer_with_multi_ai(influencer_data: Dict) -> Dict:
    """ë©€í‹° AIë¥¼ í™œìš©í•œ ì¸í”Œë£¨ì–¸ì„œ ë¶„ì„"""
    analyzer = MultiAIAnalyzer()
    
    # ì¢…í•© ë¶„ì„ ìˆ˜í–‰
    result = await analyzer.analyze_influencer_comprehensive(influencer_data)
    
    # ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±
    if "error" not in result:
        report = await analyzer.generate_detailed_report(influencer_data, result)
        result["detailed_report"] = report
    
    return result

async def get_ai_recommendations(category: str, metrics: Dict) -> List[str]:
    """AI ê¸°ë°˜ ë§ì¶¤ ì¶”ì²œ ìƒì„±"""
    analyzer = MultiAIAnalyzer()
    
    # ê°„ë‹¨í•œ ì¶”ì²œ ìƒì„±
    recommendations = []
    
    if metrics.get('engagement_rate', 0) < 3:
        recommendations.append("ì°¸ì—¬ìœ¨ í–¥ìƒì„ ìœ„í•´ íŒ”ë¡œì›Œì™€ì˜ ìƒí˜¸ì‘ìš© ì¦ëŒ€ í•„ìš”")
    
    if metrics.get('followers', 0) < 10000:
        recommendations.append("ì½œë¼ë³´ë ˆì´ì…˜ê³¼ í•´ì‹œíƒœê·¸ ìµœì í™”ë¡œ íŒ”ë¡œì›Œ ì„±ì¥ ê°€ì†í™”")
    
    if category in ['ë¨¹ë°©', 'ìŒì‹']:
        recommendations.extend([
            "ASMR ìš”ì†Œë¥¼ ì¶”ê°€í•œ ë¨¹ë°© ì½˜í…ì¸  ì œì‘",
            "ë§›ì§‘ ìœ„ì¹˜ ì •ë³´ì™€ ê°€ê²© ì •ë³´ í¬í•¨",
            "ì‹œì¦ˆë„ ë©”ë‰´ì™€ ì‹ ë©”ë‰´ ë¦¬ë·° ê°•í™”"
        ])
    elif category in ['íŒ¨ì…˜', 'ë·°í‹°']:
        recommendations.extend([
            "ì‹œì¦Œë³„ íŠ¸ë Œë“œ ì•„ì´í…œ ì†Œê°œ",
            "ìŠ¤íƒ€ì¼ë§ íŒê³¼ ì½”ë””ë²• ê³µìœ ",
            "ë¸Œëœë“œ ì½œë¼ë³´ë ˆì´ì…˜ ì ê·¹ ì¶”ì§„"
        ])
    
    return recommendations[:5]